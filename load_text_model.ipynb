{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fb8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import bert\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bdd460d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_220 (Embedding)    multiple                  7935720   \n",
      "_________________________________________________________________\n",
      "conv1d_660 (Conv1D)          multiple                  26050     \n",
      "_________________________________________________________________\n",
      "conv1d_661 (Conv1D)          multiple                  39050     \n",
      "_________________________________________________________________\n",
      "conv1d_662 (Conv1D)          multiple                  52050     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_220 (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_440 (Dense)            multiple                  38656     \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_441 (Dense)            multiple                  257       \n",
      "=================================================================\n",
      "Total params: 8,091,783\n",
      "Trainable params: 8,091,783\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('models/text_model_1')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa4ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make pre-train for bert\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b9053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0c0f211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1045,\n",
       " 2572,\n",
       " 2667,\n",
       " 2000,\n",
       " 3443,\n",
       " 1037,\n",
       " 4800,\n",
       " 3830,\n",
       " 3793,\n",
       " 5579,\n",
       " 2944,\n",
       " 1999,\n",
       " 23435,\n",
       " 12314,\n",
       " 1012,\n",
       " 1045,\n",
       " 2001,\n",
       " 2025,\n",
       " 2469,\n",
       " 2065,\n",
       " 1045,\n",
       " 2323,\n",
       " 2224,\n",
       " 23435,\n",
       " 12314,\n",
       " 2030,\n",
       " 1052,\n",
       " 22123,\n",
       " 2953,\n",
       " 2818,\n",
       " 1010,\n",
       " 1045,\n",
       " 2787,\n",
       " 2000,\n",
       " 2224,\n",
       " 23435,\n",
       " 12314,\n",
       " 2138,\n",
       " 1045,\n",
       " 2572,\n",
       " 2062,\n",
       " 5220,\n",
       " 2007,\n",
       " 2009,\n",
       " 1012,\n",
       " 1045,\n",
       " 2572,\n",
       " 5604,\n",
       " 2023,\n",
       " 2944,\n",
       " 2007,\n",
       " 1996,\n",
       " 2489,\n",
       " 16044,\n",
       " 2951,\n",
       " 13462,\n",
       " 1998,\n",
       " 6415,\n",
       " 8296,\n",
       " 1012,\n",
       " 2003,\n",
       " 2023,\n",
       " 1996,\n",
       " 2190,\n",
       " 2944,\n",
       " 2005,\n",
       " 2026,\n",
       " 2224,\n",
       " 2553,\n",
       " 1029]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "    I am trying to create a multi label text classification model in tensorflow. I was not sure if I should use\n",
    "    Tensorflow or PyTorch, I decided to use Tensorflow because I am more familiar with it. I am testing this model\n",
    "    with the freecode dataset and TagBERT. Is this the best model for my use case?\n",
    "    \"\"\"\n",
    "\n",
    "the_tokens = tokenize_data(s)\n",
    "the_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a014a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 16:12:56.777186: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n",
      "2022-01-03 16:12:57.399009: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.43726867]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTION_BATCH_SIZE = 512\n",
    "chunk = [the_tokens]\n",
    "processed_chunk_dataset = tf.data.Dataset.from_generator(lambda: chunk, output_types=(tf.int32))\n",
    "batched_chunk_dataset = processed_chunk_dataset.padded_batch(PREDICTION_BATCH_SIZE, padded_shapes=(None,))\n",
    "\n",
    "# rows = text_model.predict(batched_chunk_dataset, batch_size=len(chunk))\n",
    "model.predict(batched_chunk_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5bde2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
